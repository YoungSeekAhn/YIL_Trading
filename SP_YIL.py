
# sp_yil_batch_training program

import os
import sys
import traceback
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
from typing import Optional

from pykrx import stock

from makedata.sel_stock_ndays import sel_stock
from DSConfig_3 import config
from makedata.dataset_functions import last_trading_day
from makedata.get_dataset_2 import get_dataset
from makedata.make_dataset_3 import make_datasets
from train_LSTM.train_lstm_3 import training_LSTM
from predict_result.predict_report import predict_report
from predict_result.predict_result import predict_result
from trading_report.report_trade_price import report_trade_price
from makedata.report_sel_stock import report_sel_stock

# =========================
# ì‚¬ìš©ì ì„¤ì •
# =========================
TOP_N = 20
DURATION_DAYS = 365 * 2          # ë°ì´í„° ê¸°ê°„
SAVE_CSV_FILE = True             # get_dataset ìˆ˜ì§‘ CSV ì €ì¥ ì—¬ë¶€
FORCE_REBUILD_DATASET = False    # Trueë©´ ê¸°ì¡´ .pkl ìˆì–´ë„ ìƒˆë¡œ make_datasets
PLOT_ROLLING = False             # (ì‚¬ìš© ì¤‘ì´ë©´) ë¡¤ë§ ì°¨íŠ¸ ê·¸ë¦´ì§€ ì—¬ë¶€

TEST_MODE = False               # Trueë©´ end_dateë¥¼ 20250924ë¡œ ê³ ì • (í…ŒìŠ¤íŠ¸ìš©)

# =========================
# ìœ í‹¸
# =========================
def _ensure_code(code_or_none: Optional[str], name: str) -> str:
    """CSVì— Codeê°€ ë¹„ì–´ ìˆìœ¼ë©´ ì¢…ëª©ëª…ìœ¼ë¡œ pykrxì—ì„œ ì½”ë“œ ì¡°íšŒ."""
    if code_or_none and str(code_or_none).strip():
        code = str(code_or_none).strip()
        # 6ìë¦¬ zero-pad ë³´ì •
        if code.isdigit() and len(code) < 6:
            code = code.zfill(6)
        return code

    tickers = stock.get_market_ticker_list(market="ALL")
    mapping = {stock.get_market_ticker_name(t): t for t in tickers}
    if name not in mapping:
        raise ValueError(f"ì¢…ëª© '{name}'ì˜ ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return mapping[name]

def _compute_dates():
    end_date = last_trading_day()  # "YYYYMMDD"
    
    if TEST_MODE:
        end_date = "20250924"
    
    start_dt = datetime.strptime(end_date, "%Y%m%d") - timedelta(days=config.duration)
    start_date = start_dt.strftime("%Y%m%d")
    
    config.start_date = start_date
    config.end_date = end_date
    return start_date, end_date

def _paths_for(config) -> tuple[Path, Path]:
    """ì¢…ëª©ë³„ ìˆ˜ì§‘ CSV, í•™ìŠµ pkl ê²½ë¡œ ë°˜í™˜"""
    get_dir = Path(config.getdata_dir) / f"{config.end_date}"
    dataset_dir = Path(config.dataset_dir) / f"{config.end_date}"
    get_dir.mkdir(parents=True, exist_ok=True)
    dataset_dir.mkdir(parents=True, exist_ok=True)
    csvpath = get_dir / f"{config.name}({config.code})_{config.end_date}.csv"
    datapath = dataset_dir / f"{config.name}({config.code})_{config.end_date}.pkl"
    return csvpath, datapath

def run_for_one(name: str, code: Optional[str]):
    # ----- ì½”ë“œ/ê¸°ê°„/ì„¤ì • ì„¸íŒ… -----
    code = _ensure_code(code, name)
    start_date = config.start_date
    end_date = config.end_date

    # DSConfig ê°±ì‹  (ì£¼ì˜: ì „ì—­ config ê°ì²´ë¥¼ ë£¨í”„ë§ˆë‹¤ ì—…ë°ì´íŠ¸)
    config.name = name
    config.code = code

    # # í•„ìš” ì‹œ ì¶”ê°€ ì˜µì…˜ë„ ë™ê¸°í™”
    # if hasattr(config, "plot_rolling"):
    #     config.plot_rolling = PLOT_ROLLING

    csvpath, datapath = _paths_for(config)

    print(f"\n=== [{name} ({code})] {start_date}~{end_date} ì‹œì‘ ===")
    print(f"- CSV: {csvpath}")
    print(f"- PKL: {datapath}")

    # ----- ì›ì²œ ë°ì´í„° CSV ìƒì„±/ì¡´ì¬ í™•ì¸ -----
    merged_df = None
    if not csvpath.exists():
        print("â†’ ìˆ˜ì§‘ CSV ì—†ìŒ â†’ get_dataset ì‹¤í–‰")
        merged_df = get_dataset(config, SAVE_CSV_FILE=SAVE_CSV_FILE)
        print(f"   [OK] ìˆ˜ì§‘ CSV ìƒì„± ì™„ë£Œ: {csvpath}")
    else:
        print("â†’ ìˆ˜ì§‘ CSV ì´ë¯¸ ì¡´ì¬ (ì¬ìˆ˜ì§‘ ìƒëµ). í•„ìš” ì‹œ get_datasetë¡œ ê°±ì‹  ê°€ëŠ¥")

    # ----- í•™ìŠµ ë°ì´í„°ì…‹ ìƒì„±/ë¡œë“œ -----
    payload = None
    if FORCE_REBUILD_DATASET or (not datapath.exists()):
        print("â†’ í•™ìŠµ pkl ì—†ìŒ ë˜ëŠ” ì¬ìƒì„± ê°•ì œ â†’ make_datasets(LOAD_CSV_FILE=False)")
        # merged_dfê°€ Noneì´ë¼ë©´ make_datasets ë‚´ë¶€ì—ì„œ csvpathë¥¼ ì‚¬ìš©í•˜ë„ë¡ êµ¬í˜„ë˜ì–´ ìˆë‹¤ë©´ OK.
        # ì•„ë‹ˆë¼ë©´ ë‹¤ìŒ ì¤„ì—ì„œ CSVë¥¼ ì½ì–´ merged_dfë¥¼ ë§Œë“¤ì–´ ì „ë‹¬í•˜ì„¸ìš”.
        # merged_df = pd.read_csv(csvpath, index_col=0, parse_dates=True)
        payload = make_datasets(merged_df, config, LOAD_CSV_FILE=False)
        print(f"   [OK] í•™ìŠµ pkl ìƒì„± ì™„ë£Œ: {datapath}")
            # ----- í•™ìŠµ -----
        print("â†’ training_LSTM ì‹œì‘")
        training_LSTM(payload, config)
        print(f"[DONE] {name} ({code})")
    else:
        print("â†’ í•™ìŠµ pkl ì´ë¯¸ ì¡´ì¬ â†’ make_datasets(LOAD_CSV_FILE=True)ë¡œ ë¡œë“œ ì‹œë„")
        # NOTE: make_datasetsê°€ LOAD_CSV_FILE=Trueì¼ ë•Œ pklì„ ë¡œë“œí•´ payloadë¥¼ ë°˜í™˜í•˜ë„ë¡
        # êµ¬í˜„ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ê·¸ë ‡ì§€ ì•Šë‹¤ë©´ ì§ì ‘ pickle ë¡œë”© ì½”ë“œë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
        payload = make_datasets(None, config, LOAD_CSV_FILE=True)
        print("   [OK] ê¸°ì¡´ pkl ë¡œë“œ ì™„ë£Œ")
        print(" [SKIP] í•™ìŠµ pklì´ ì´ë¯¸ ì¡´ì¬í•˜ë¯€ë¡œ ì¬ìƒì„± ë° í•™ìŠµ ìƒëµ")
    

# =========================
# ë©”ì¸ ì‹¤í–‰
# =========================
def main():
    # ì„ ì • CSV ë¡œë“œ
    #  CSVëŠ” sel_stock_ndays.py ê²°ê³¼ë¬¼ì´ì–´ì•¼ í•¨
    start_date, end_date= _compute_dates()
    
    config.start_date = start_date
    config.end_date = end_date
    
    sel_dir = Path(config.selout_dir)
    SEL_CSV_PATH = os.path.join(sel_dir, f"scored_{end_date}.csv")
    
    if not os.path.exists(SEL_CSV_PATH):
        #raise FileNotFoundError(f"ì„ ì • CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {SEL_CSV_PATH}")
        sel_stock(config)  # ì„ ì • CSV ìƒì„± ì‹œë„
        report_sel_stock(config)  # ì„ ì • ë¦¬í¬íŠ¸ ìƒì„± ì‹œë„

    sel = pd.read_csv(SEL_CSV_PATH, dtype={"Code": str})
    # ì•ˆì „í•œ ì •ë ¬ (Score_1w ë‚´ë¦¼ì°¨ìˆœ)
    if "Score_1w" not in sel.columns:
        raise ValueError("CSVì— 'Score_1w' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    sel = sel.sort_values(by="Score_1w", ascending=False).reset_index(drop=True)

    # ìƒìœ„ N ì¶”ì¶œ (Name, Codeë§Œ í•„ìš”)
    cols_needed = ["Name", "Code"]
    for c in cols_needed:
        if c not in sel.columns:
            raise ValueError(f"CSVì— '{c}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    top = sel.loc[:TOP_N - 1, cols_needed].copy()

    print("===============================================")
    print(f"sel_stock_ndays ìƒìœ„ {TOP_N} ì¢…ëª© í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("===============================================")
    results = []
    for i, row in top.iterrows():
        name = str(row["Name"]).strip()
        code = None if pd.isna(row["Code"]) else str(row["Code"]).strip()
        try:
            run_for_one(name, code)
            results.append((name, code, "OK", ""))
        except Exception as e:
            err = "".join(traceback.format_exception_only(type(e), e)).strip()
            print(f"[ERROR] {name} ì‹¤íŒ¨: {err}")
            # ìŠ¤íƒ ìš”ì•½ ë¡œê·¸ (í•„ìš” ì‹œ ìƒì„¸ traceback.print_exc())
            traceback.print_exc()
            results.append((name, code, "FAIL", err))

    # ìš”ì•½
    print("\n=========== ë°°ì¹˜ ìš”ì•½ ===========")
    ok = [r for r in results if r[2] == "OK"]
    fail = [r for r in results if r[2] == "FAIL"]
    for tag, arr in [("ì„±ê³µ", ok), ("ì‹¤íŒ¨", fail)]:
        print(f"\n[{tag} {len(arr)}]")
        for (n, c, _, msg) in arr:
            print(f"- {n} ({c}) {('â†’ ' + msg) if msg else ''}")

    # LSTM í•™ìŠµ/ì˜ˆì¸¡ ê²°ê³¼ í‰ê°€ ë° ë¦¬í¬íŠ¸
    # predict_result(config) í•¨ìˆ˜ í¬í•¨ë¨
    print("\n=========== ì˜ˆì¸¡ ê²°ê³¼ í‰ê°€ ë° ë¦¬í¬íŠ¸ ===========")
    predict_report(config)
    
    # ê±°ë˜ ê°€ê²© ë¦¬í¬íŠ¸
    # make_trade_price() í•¨ìˆ˜ í¬í•¨ë¨
    print("\n=========== ê±°ë˜ ê°€ê²© ë¦¬í¬íŠ¸ ===========")
    report_trade_price(config)
    

import schedule
import time
import argparse
from datetime import datetime

def run_job():
    print(f"[RUN] main() ì‹¤í–‰ ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')})")
    main()

if __name__ == "__main__":
    # ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±
    ap = argparse.ArgumentParser(description="ìë™ë§¤ë§¤ ìŠ¤ì¼€ì¤„ëŸ¬")
    ap.add_argument("--start", default="22:00", help="ì‹œì‘ ì‹œê°„ (HH:MM í˜•ì‹, ê¸°ë³¸ê°’ 22:00)")
    args = ap.parse_args()

    # ì…ë ¥ ê²€ì¦
    try:
        hour, minute = map(int, args.start.split(":"))
        assert 0 <= hour < 24 and 0 <= minute < 60
    except Exception:
        print("âŒ ì‹œì‘ ì‹œê°„ í˜•ì‹ ì˜¤ë¥˜. ì˜ˆì‹œ: --start 21:30")
        exit(1)

    print(f"ğŸ•’ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘: ë§¤ì¼ {args.start}ì— main() ì‹¤í–‰")

    # ìŠ¤ì¼€ì¤„ ë“±ë¡
    schedule.every().day.at(args.start).do(run_job)

    # ë¬´í•œ ë£¨í”„ (1ë¶„ ë‹¨ìœ„ë¡œ í™•ì¸)
    while True:
        schedule.run_pending()
        time.sleep(60)

# py -m PyInstaller --onefile SP_YIL.py

# python -m PyInstaller ^
#  --noconfirm ^
#  --clean ^
#  --noconsole ^
#  --icon=icon.ico ^
#  --add-data "config/.env;config/" ^
#  src/auto_trader.py